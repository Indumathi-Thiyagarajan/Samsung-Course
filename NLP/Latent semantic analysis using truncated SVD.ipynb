{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition  import TruncatedSVD\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Latent Semantic Analysis (LSA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data.\n",
    "my_docs = [\"The economic slowdown is becoming more severe\",\n",
    "           \"The movie was simply awesome\",\n",
    "           \"I like cooking my own food\",\n",
    "           \"Samsung is announcing a new technology\",\n",
    "           \"Machine Learning is an example of awesome technology\",\n",
    "           \"All of us were excited at the movie\",\n",
    "           \"We have to do more to reverse the economic slowdown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Create a TF IDF representation:\n",
    "TfidfVectorizer() arguments: <br>\n",
    "- *max_features* : maximum number of features (distict words). <br>\n",
    "- *min_df* : The minimum DF. Integer value means count and real number (0~1) means proportion. <br> \n",
    "- *max_df* : The maximum DF. Integer value means count and real number (0~1) means proportion. Helps to filter out the stop words. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_docs = [x.lower() for x in my_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ['us', 'like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 15, min_df = 1, max_df = 3, stop_words = stopwords.words('english') + my_stop_words)\n",
    "X = vectorizer.fit_transform(my_docs).toarray()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of X (=m x n). m = number of documents = 7 & n = number of features.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['announcing', 'awesome', 'cooking', 'economic', 'example', 'excited', 'food', 'movie', 'new', 'reverse', 'samsung', 'severe', 'simply', 'slowdown', 'technology']\n"
     ]
    }
   ],
   "source": [
    "# View the features.\n",
    "features = vectorizer.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Apply the truncated SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=4, n_iter=100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 4\n",
    "svd = TruncatedSVD(n_components=n_topics, n_iter=100)\n",
    "svd.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the V^t matrix. \n",
    "vt = svd.components_\n",
    "vtabs = np.abs(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the size of V^t. \n",
    "vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.62288440e-17,  9.50380366e-18, -2.23871986e-18,\n",
       "         6.05710899e-01,  9.75226714e-18,  9.62765708e-19,\n",
       "        -2.23871986e-18,  2.35367156e-18,  4.27290993e-17,\n",
       "         3.64848333e-01,  4.27290993e-17,  3.64848333e-01,\n",
       "         1.94918609e-18,  6.05710899e-01,  4.34982063e-17],\n",
       "       [ 1.09328020e-01,  5.24120449e-01, -4.92767842e-17,\n",
       "         9.37746298e-18,  2.79641926e-01,  3.00367284e-01,\n",
       "        -4.92767842e-17,  5.41324276e-01,  1.09328020e-01,\n",
       "         1.69334126e-17,  1.09328020e-01, -1.55329901e-17,\n",
       "         3.51763163e-01,  9.37746298e-18,  3.22878460e-01],\n",
       "       [ 3.17757779e-01,  1.09242359e-01, -2.11112265e-15,\n",
       "        -2.33185786e-17,  2.84805383e-01, -3.73322920e-01,\n",
       "        -2.11227461e-15, -4.37060653e-01,  3.17757779e-01,\n",
       "        -7.57931141e-17,  3.17757779e-01,  3.87128567e-17,\n",
       "        -1.53201700e-01, -2.33185919e-17,  5.00179172e-01],\n",
       "       [ 6.49154587e-16,  4.20169827e-16,  7.07106781e-01,\n",
       "         1.60752623e-17,  1.05982378e-15, -9.84630874e-16,\n",
       "         7.07106781e-01, -1.25864205e-15,  6.25103405e-16,\n",
       "         5.02952375e-18,  6.25103405e-16, -3.64818441e-18,\n",
       "        -5.46172386e-16, -1.16803142e-17,  1.41349634e-15]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. From each topic, extract the top features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 3\n",
    "for i in range(n_topics):\n",
    "    topic_features = [features[idx] for idx in np.argsort(-vtabs[i,:])]   # argsort() shows the sorted index.\n",
    "    topic_features_top = topic_features[0:n_top]\n",
    "    if i == 0:\n",
    "        topic_matrix = [topic_features_top]                    # list의 list 만들 준비!\n",
    "    else:\n",
    "        topic_matrix.append(topic_features_top) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top features for each topic.\n",
    "topic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In view of the top features, we can name the topics.\n",
    "topic_names = ['Economy', 'Movie','Technology', 'Cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Label each document with the most predominant topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = len(my_docs)\n",
    "for i in range(n_docs):\n",
    "    score_pick = 0\n",
    "    topic_pick = 0\n",
    "    tokennized_doc = nltk.word_tokenize(my_docs[i])\n",
    "    for j in range(n_topics):\n",
    "        found = [ x in topic_matrix[j] for x in tokennized_doc ] \n",
    "        score = np.sum(found)\n",
    "        if (score > score_pick):\n",
    "            score_pick = score\n",
    "            topic_pick = j\n",
    "    print(\"Document \" + str(i+1) + \" = \" + topic_names[topic_pick])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: We can notice some inaccuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
